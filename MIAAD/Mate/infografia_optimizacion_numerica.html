<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M√©todos de Optimizaci√≥n Num√©rica | UACJ MIAAD</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700;800&family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'base',
            themeVariables: {
                primaryColor: '#415a77',
                primaryTextColor: '#0d1b2a',
                primaryBorderColor: '#778da9',
                lineColor: '#1b263b',
                secondaryColor: '#e0e1dd',
                tertiaryColor: '#778da9',
                fontSize: '14px',
                fontFamily: 'Inter, sans-serif'
            }
        });
    </script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --rich-black: #0d1b2a;
            --oxford-blue: #1b263b;
            --yinmn-blue: #415a77;
            --silver-lake-blue: #778da9;
            --platinum: #e0e1dd;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, var(--rich-black) 0%, var(--oxford-blue) 100%);
            color: var(--rich-black);
            line-height: 1.6;
            padding: 0;
            min-height: 100vh;
        }

        .container {
            max-width: 1600px;
            margin: 0 auto;
            background: var(--platinum);
            box-shadow: 0 25px 70px rgba(0, 0, 0, 0.4);
        }

        /* HEADER INSTITUCIONAL */
        .institutional-header {
            background: white;
            padding: 20px 50px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 3px solid var(--yinmn-blue);
            flex-wrap: wrap;
            gap: 20px;
        }

        .logo-container {
            display: flex;
            align-items: center;
            gap: 30px;
        }

        .uacj-logo {
            height: 80px;
            width: auto;
        }

        .miaad-logo {
            height: 70px;
            width: auto;
            border-radius: 8px;
        }

        .program-info {
            text-align: right;
            flex: 1;
        }

        .program-info h2 {
            font-family: 'Poppins', sans-serif;
            font-size: 1.1em;
            font-weight: 700;
            color: var(--yinmn-blue);
            margin-bottom: 5px;
            letter-spacing: -0.5px;
        }

        .program-info p {
            font-size: 0.85em;
            color: var(--silver-lake-blue);
            font-weight: 500;
        }

        /* MAIN HEADER */
        header {
            background: linear-gradient(135deg, var(--rich-black) 0%, var(--oxford-blue) 50%, var(--yinmn-blue) 100%);
            color: white;
            padding: 60px 50px;
            position: relative;
            overflow: hidden;
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 50%;
            height: 100%;
            background: linear-gradient(135deg, transparent 0%, rgba(65, 90, 119, 0.2) 100%);
            transform: skewX(-15deg);
            transform-origin: top right;
        }

        .header-content {
            position: relative;
            z-index: 1;
            max-width: 1400px;
            margin: 0 auto;
        }

        header h1 {
            font-family: 'Poppins', sans-serif;
            font-size: 3.5em;
            font-weight: 800;
            margin-bottom: 15px;
            letter-spacing: -2px;
            line-height: 1.1;
        }

        .header-subtitle {
            font-size: 1.3em;
            font-weight: 300;
            margin-bottom: 30px;
            color: var(--platinum);
            letter-spacing: 0.5px;
        }

        /* STUDENT INFO CARD */
        .student-card {
            background: white;
            border-radius: 15px;
            padding: 30px;
            margin: 0 50px;
            margin-top: -40px;
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.2);
            position: relative;
            z-index: 10;
            display: flex;
            align-items: center;
            gap: 30px;
            border-left: 5px solid var(--yinmn-blue);
        }

        .student-photo {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: 4px solid var(--yinmn-blue);
            object-fit: cover;
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
        }

        .student-info-content {
            flex: 1;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
        }

        .info-item {
            display: flex;
            flex-direction: column;
        }

        .info-label {
            font-size: 0.75em;
            font-weight: 700;
            color: var(--silver-lake-blue);
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 3px;
        }

        .info-value {
            font-size: 1.05em;
            font-weight: 600;
            color: var(--rich-black);
        }

        .info-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: var(--yinmn-blue);
            text-decoration: none;
            font-weight: 600;
            margin-top: 15px;
            padding: 10px 20px;
            background: var(--platinum);
            border-radius: 8px;
            transition: all 0.3s ease;
            border: 2px solid var(--yinmn-blue);
        }

        .info-link:hover {
            background: var(--yinmn-blue);
            color: white;
            transform: translateX(5px);
        }

        /* INTRO SECTION */
        .intro {
            padding: 60px 50px;
            text-align: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        .intro h2 {
            font-family: 'Poppins', sans-serif;
            font-size: 2.5em;
            font-weight: 700;
            color: var(--rich-black);
            margin-bottom: 20px;
            letter-spacing: -1px;
        }

        .intro p {
            font-size: 1.15em;
            color: var(--oxford-blue);
            line-height: 1.8;
            font-weight: 400;
        }

        /* METHODS SECTION */
        .methods-section {
            padding: 40px 50px 80px;
            background: white;
        }

        .method-card {
            max-width: 1400px;
            margin: 0 auto 60px;
            background: var(--platinum);
            border-radius: 20px;
            overflow: hidden;
            box-shadow: 0 10px 40px rgba(13, 27, 42, 0.15);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            border: 1px solid rgba(65, 90, 119, 0.2);
        }

        .method-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 60px rgba(13, 27, 42, 0.25);
        }

        .method-header {
            background: linear-gradient(135deg, var(--oxford-blue) 0%, var(--yinmn-blue) 100%);
            color: white;
            padding: 40px 50px;
            position: relative;
            overflow: hidden;
        }

        .method-header::after {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 40%;
            height: 100%;
            background: linear-gradient(135deg, transparent 0%, rgba(255, 255, 255, 0.1) 100%);
            transform: skewX(-15deg);
        }

        .method-number {
            font-size: 1em;
            font-weight: 700;
            color: var(--platinum);
            opacity: 0.8;
            letter-spacing: 2px;
            margin-bottom: 10px;
        }

        .method-title {
            font-family: 'Poppins', sans-serif;
            font-size: 2.5em;
            font-weight: 800;
            margin: 0;
            letter-spacing: -1px;
            position: relative;
            z-index: 1;
        }

        .method-body {
            padding: 50px;
        }

        .method-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            margin-bottom: 40px;
        }

        .section-box {
            background: white;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 4px 15px rgba(13, 27, 42, 0.08);
            border-left: 4px solid var(--yinmn-blue);
        }

        .section-title {
            font-family: 'Poppins', sans-serif;
            font-size: 1.4em;
            font-weight: 700;
            color: var(--rich-black);
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .section-icon {
            font-size: 1.2em;
        }

        .description-text {
            font-size: 1.05em;
            line-height: 1.8;
            color: var(--oxford-blue);
        }

        /* FORMULAS */
        .formula-container {
            background: linear-gradient(135deg, var(--rich-black) 0%, var(--oxford-blue) 100%);
            border-radius: 12px;
            padding: 25px;
            margin: 15px 0;
            border: 2px solid var(--yinmn-blue);
        }

        .formula-main {
            font-family: 'Courier New', monospace;
            font-size: 1.4em;
            font-weight: bold;
            color: white;
            text-align: center;
            margin-bottom: 15px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
        }

        .formula-explanation {
            font-size: 0.95em;
            color: var(--platinum);
            line-height: 1.8;
        }

        .formula-explanation strong {
            color: white;
        }

        /* PROS & CONS */
        .pros-cons-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 25px;
        }

        .pros-box, .cons-box {
            border-radius: 12px;
            padding: 25px;
            border: 2px solid;
        }

        .pros-box {
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border-color: #28a745;
        }

        .cons-box {
            background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);
            border-color: #dc3545;
        }

        .pros-title, .cons-title {
            font-family: 'Poppins', sans-serif;
            font-size: 1.2em;
            font-weight: 700;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .pros-title {
            color: #155724;
        }

        .cons-title {
            color: #721c24;
        }

        ul {
            list-style: none;
            padding-left: 0;
        }

        li {
            padding-left: 25px;
            margin: 10px 0;
            position: relative;
            font-size: 1em;
            line-height: 1.6;
        }

        .pros-box li::before {
            content: '‚úì';
            position: absolute;
            left: 0;
            color: #28a745;
            font-weight: bold;
            font-size: 1.2em;
        }

        .cons-box li::before {
            content: '‚úó';
            position: absolute;
            left: 0;
            color: #dc3545;
            font-weight: bold;
            font-size: 1.2em;
        }

        /* APPLICATIONS */
        .applications-box {
            background: linear-gradient(135deg, var(--yinmn-blue) 0%, var(--silver-lake-blue) 100%);
            border-radius: 12px;
            padding: 30px;
            color: white;
        }

        .applications-title {
            font-family: 'Poppins', sans-serif;
            font-size: 1.4em;
            font-weight: 700;
            margin-bottom: 20px;
        }

        .app-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            margin-bottom: 20px;
        }

        .app-tag {
            background: white;
            color: var(--rich-black);
            padding: 8px 18px;
            border-radius: 25px;
            font-size: 0.9em;
            font-weight: 600;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
        }

        .app-description {
            font-size: 1.05em;
            line-height: 1.7;
            color: var(--platinum);
        }

        /* VISUALIZATION MERMAID */
        .visualization-section {
            background: white;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 4px 15px rgba(13, 27, 42, 0.08);
            grid-column: 1 / -1;
        }

        .visualization-title {
            font-family: 'Poppins', sans-serif;
            font-size: 1.4em;
            font-weight: 700;
            color: var(--rich-black);
            margin-bottom: 20px;
            text-align: center;
        }

        .mermaid {
            display: flex;
            justify-content: center;
            background: var(--platinum);
            padding: 30px;
            border-radius: 10px;
        }

        /* COMPARISON TABLE */
        .comparison-section {
            padding: 60px 50px;
            background: linear-gradient(135deg, var(--platinum) 0%, white 100%);
        }

        .comparison-title {
            font-family: 'Poppins', sans-serif;
            font-size: 2.5em;
            font-weight: 700;
            color: var(--rich-black);
            text-align: center;
            margin-bottom: 40px;
            letter-spacing: -1px;
        }

        .table-container {
            max-width: 1400px;
            margin: 0 auto;
            overflow-x: auto;
            box-shadow: 0 15px 40px rgba(13, 27, 42, 0.15);
            border-radius: 15px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            background: white;
        }

        thead {
            background: linear-gradient(135deg, var(--rich-black) 0%, var(--oxford-blue) 100%);
            color: white;
        }

        th {
            padding: 20px;
            text-align: left;
            font-family: 'Poppins', sans-serif;
            font-weight: 700;
            font-size: 1.05em;
            letter-spacing: 0.5px;
        }

        th:first-child {
            border-top-left-radius: 15px;
        }

        th:last-child {
            border-top-right-radius: 15px;
        }

        td {
            padding: 18px 20px;
            border-bottom: 1px solid var(--platinum);
            font-size: 1em;
        }

        tbody tr {
            transition: background 0.2s ease;
        }

        tbody tr:hover {
            background: var(--platinum);
        }

        tbody tr:last-child td {
            border-bottom: none;
        }

        tbody tr:last-child td:first-child {
            border-bottom-left-radius: 15px;
        }

        tbody tr:last-child td:last-child {
            border-bottom-right-radius: 15px;
        }

        td:first-child {
            font-weight: 700;
            color: var(--rich-black);
        }

        .rating {
            color: #ffd700;
            font-size: 1.1em;
        }

        /* FOOTER */
        footer {
            background: var(--rich-black);
            color: white;
            padding: 60px 50px 40px;
        }

        .footer-content {
            max-width: 1400px;
            margin: 0 auto;
        }

        .references-section {
            margin-bottom: 40px;
        }

        .references-title {
            font-family: 'Poppins', sans-serif;
            font-size: 2em;
            font-weight: 700;
            margin-bottom: 30px;
            color: var(--platinum);
        }

        .references-list {
            list-style: none;
            padding: 0;
        }

        .references-list li {
            padding: 20px;
            background: var(--oxford-blue);
            border-radius: 10px;
            margin-bottom: 15px;
            border-left: 4px solid var(--yinmn-blue);
            line-height: 1.8;
        }

        .references-list li::before {
            display: none;
        }

        .references-list a {
            color: var(--platinum);
            text-decoration: none;
            border-bottom: 1px dotted var(--silver-lake-blue);
            transition: color 0.3s ease;
        }

        .references-list a:hover {
            color: var(--silver-lake-blue);
        }

        .ref-note {
            display: block;
            font-size: 0.9em;
            color: var(--silver-lake-blue);
            margin-top: 8px;
            font-style: italic;
        }

        .footer-info {
            text-align: center;
            padding: 30px;
            background: var(--oxford-blue);
            border-radius: 10px;
            margin-top: 40px;
        }

        .footer-logos {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 40px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .footer-logo {
            height: 60px;
            width: auto;
        }

        /* RESPONSIVE */
        @media (max-width: 1200px) {
            .method-grid {
                grid-template-columns: 1fr;
            }

            .pros-cons-grid {
                grid-template-columns: 1fr;
            }
        }

        @media (max-width: 768px) {
            .institutional-header {
                padding: 15px 20px;
            }

            .logo-container {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }

            .program-info {
                text-align: center;
            }

            header {
                padding: 40px 20px;
            }

            header h1 {
                font-size: 2.2em;
            }

            .student-card {
                flex-direction: column;
                margin: 0 20px;
                margin-top: -30px;
                padding: 20px;
            }

            .student-info-content {
                grid-template-columns: 1fr;
            }

            .intro, .methods-section, .comparison-section, footer {
                padding: 40px 20px;
            }

            .method-body {
                padding: 25px;
            }

            th, td {
                font-size: 0.85em;
                padding: 12px;
            }
        }

        /* ANIMATIONS */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .method-card {
            animation: fadeIn 0.6s ease-out;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- HEADER INSTITUCIONAL -->
        <div class="institutional-header">
            <div class="logo-container">
                <img src="https://www.uacj.mx/acerca_de/Imagen-Institucional-UACJ_files/firma%20institucional%20uacj-vertical-%202015-color-sin%20fondo.png" 
                     alt="Logo UACJ" class="uacj-logo">
                <img src="https://media.licdn.com/dms/image/v2/D560BAQGT-hIyClMhDg/company-logo_400_400/B56ZUrUBmmGQAY-/0/1740188424995?e=2147483647&v=beta&t=WdaQxhUQ6hOSC2RPMI20RCKtFtgRuKZe7rssOYykFWU" 
                     alt="Logo MIAAD" class="miaad-logo">
            </div>
            <div class="program-info">
                <h2>Maestr√≠a en Inteligencia Artificial y Anal√≠tica de Datos</h2>
                <p>Universidad Aut√≥noma de Ciudad Ju√°rez</p>
            </div>
        </div>

        <!-- MAIN HEADER -->
        <header>
            <div class="header-content">
                <h1>M√©todos de Optimizaci√≥n Num√©rica</h1>
                <p class="header-subtitle">Fundamentos Matem√°ticos para Inteligencia Artificial y Machine Learning</p>
            </div>
        </header>

        <!-- STUDENT CARD -->
        <div class="student-card">
            <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" class="student-photo">
            <div class="student-info-content">
                <div class="info-item">
                    <span class="info-label">Estudiante</span>
                    <span class="info-value">Javier Augusto Rebull Saucedo</span>
                </div>
                <div class="info-item">
                    <span class="info-label">Matr√≠cula</span>
                    <span class="info-value">al263483</span>
                </div>
                <div class="info-item">
                    <span class="info-label">Materia</span>
                    <span class="info-value">Matem√°ticas y Estad√≠stica para IA</span>
                </div>
                <div class="info-item">
                    <span class="info-label">Profesora</span>
                    <span class="info-value">Helen Clara Pe√±ate Rodr√≠guez</span>
                </div>
                <div class="info-item">
                    <span class="info-label">Tarea</span>
                    <span class="info-value">Week 10 - Task 011</span>
                </div>
                <div class="info-item">
                    <span class="info-label">Fecha</span>
                    <span class="info-value">19 de Octubre 2025</span>
                </div>
            </div>
            <a href="https://rebull.org/miaad/mate/infografia_optimizacion_numerica" target="_blank" class="info-link">
                üîó Ver Infograf√≠a Online
            </a>
        </div>

        <!-- INTRO -->
        <div class="intro">
            <h2>Optimizaci√≥n Num√©rica en IA</h2>
            <p>Los m√©todos de optimizaci√≥n num√©rica constituyen el n√∫cleo matem√°tico del aprendizaje autom√°tico moderno. Estos algoritmos permiten entrenar modelos complejos mediante la minimizaci√≥n iterativa de funciones de p√©rdida, ajustando millones de par√°metros para lograr predicciones precisas. Desde redes neuronales profundas hasta sistemas de recomendaci√≥n, la optimizaci√≥n num√©rica es el motor que impulsa la inteligencia artificial contempor√°nea.</p>
        </div>

        <!-- METHODS -->
        <div class="methods-section">
            <!-- M√âTODO 1: GRADIENT DESCENT -->
            <div class="method-card">
                <div class="method-header">
                    <div class="method-number">M√âTODO 01</div>
                    <h2 class="method-title">Descenso del Gradiente (Gradient Descent)</h2>
                </div>
                <div class="method-body">
                    <div class="method-grid">
                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üìã</span>
                                Descripci√≥n
                            </h3>
                            <p class="description-text">
                                El Descenso del Gradiente es el algoritmo de optimizaci√≥n fundamental en machine learning. Es un m√©todo iterativo de primer orden que actualiza los par√°metros del modelo movi√©ndose en la direcci√≥n opuesta al gradiente de la funci√≥n de costo. En su forma batch, procesa el conjunto completo de datos de entrenamiento en cada iteraci√≥n, garantizando actualizaciones estables pero computacionalmente costosas para datasets grandes.
                            </p>
                        </div>

                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üßÆ</span>
                                F√≥rmulas Principales
                            </h3>
                            <div class="formula-container">
                                <div class="formula-main">Œ∏<sub>(t+1)</sub> = Œ∏<sub>(t)</sub> - Œ∑ ‚àáJ(Œ∏<sub>(t)</sub>)</div>
                                <div class="formula-explanation">
                                    <strong>Œ∏:</strong> Vector de par√°metros del modelo<br>
                                    <strong>Œ∑:</strong> Learning rate (tasa de aprendizaje)<br>
                                    <strong>‚àáJ(Œ∏):</strong> Gradiente de la funci√≥n de costo
                                </div>
                            </div>
                            <div class="formula-container">
                                <div class="formula-main">‚àáJ(Œ∏) = (1/m) Œ£<sub>i=1</sub><sup>m</sup> ‚àáL(f(x<sup>(i)</sup>; Œ∏), y<sup>(i)</sup>)</div>
                                <div class="formula-explanation">
                                    <strong>m:</strong> Tama√±o total del dataset<br>
                                    <strong>L:</strong> Funci√≥n de p√©rdida individual
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <h3 class="section-title">
                                <span class="section-icon">‚öñÔ∏è</span>
                                An√°lisis de Ventajas y Desventajas
                            </h3>
                            <div class="pros-cons-grid">
                                <div class="pros-box">
                                    <h4 class="pros-title">‚úÖ Ventajas</h4>
                                    <ul>
                                        <li>Convergencia estable y predecible</li>
                                        <li>Garantiza convergencia al m√≠nimo global en funciones convexas</li>
                                        <li>C√°lculo preciso del gradiente usando todos los datos</li>
                                        <li>Implementaci√≥n conceptualmente simple</li>
                                        <li>Ideal para datasets peque√±os-medianos</li>
                                    </ul>
                                </div>
                                <div class="cons-box">
                                    <h4 class="cons-title">‚ùå Desventajas</h4>
                                    <ul>
                                        <li>Extremadamente lento para datasets grandes</li>
                                        <li>Costo computacional O(mn) por iteraci√≥n</li>
                                        <li>Puede quedar atrapado en m√≠nimos locales</li>
                                        <li>Sensible a la selecci√≥n del learning rate</li>
                                        <li>No escalable a problemas de big data</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <div class="applications-box">
                                <h3 class="applications-title">üéØ Aplicaciones en Machine Learning</h3>
                                <div class="app-tags">
                                    <span class="app-tag">Regresi√≥n Lineal</span>
                                    <span class="app-tag">Regresi√≥n Log√≠stica</span>
                                    <span class="app-tag">Support Vector Machines</span>
                                    <span class="app-tag">Redes Neuronales Peque√±as</span>
                                    <span class="app-tag">Optimizaci√≥n Convexa</span>
                                    <span class="app-tag">An√°lisis Predictivo</span>
                                </div>
                                <p class="app-description">
                                    Ampliamente utilizado en problemas de regresi√≥n y clasificaci√≥n con conjuntos de datos moderados. Es el m√©todo preferido cuando se requiere m√°xima precisi√≥n en la convergencia y el costo computacional no es una limitante cr√≠tica.
                                </p>
                            </div>
                        </div>

                        <div class="visualization-section">
                            <h3 class="visualization-title">üìä Flujo de Optimizaci√≥n</h3>
                            <div class="mermaid">
graph LR
    A[Inicio: Œ∏‚Å∞] --> B[Calcular J Œ∏]
    B --> C[Calcular ‚àáJ Œ∏<br/>usando TODO el dataset]
    C --> D[Actualizar:<br/>Œ∏ = Œ∏ - Œ∑‚àáJ]
    D --> E{¬øConvergencia?}
    E -->|No| B
    E -->|S√≠| F[Œ∏* √ìptimo]
    style A fill:#415a77,stroke:#0d1b2a,stroke-width:3px,color:#fff
    style F fill:#0d1b2a,stroke:#415a77,stroke-width:3px,color:#fff
    style C fill:#778da9,stroke:#0d1b2a,stroke-width:2px
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- M√âTODO 2: SGD -->
            <div class="method-card">
                <div class="method-header">
                    <div class="method-number">M√âTODO 02</div>
                    <h2 class="method-title">Descenso del Gradiente Estoc√°stico (SGD)</h2>
                </div>
                <div class="method-body">
                    <div class="method-grid">
                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üìã</span>
                                Descripci√≥n
                            </h3>
                            <p class="description-text">
                                SGD revolucion√≥ el entrenamiento de redes neuronales al realizar actualizaciones de par√°metros usando mini-batches o muestras individuales. Esta naturaleza estoc√°stica introduce ruido controlado que permite escapar de m√≠nimos locales y acelera dr√°sticamente el entrenamiento. Es el algoritmo est√°ndar en deep learning moderno, formando la base de optimizadores avanzados como Adam, RMSprop y AdaGrad.
                            </p>
                        </div>

                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üßÆ</span>
                                F√≥rmulas Principales
                            </h3>
                            <div class="formula-container">
                                <div class="formula-main">Œ∏<sub>(t+1)</sub> = Œ∏<sub>(t)</sub> - Œ∑ ‚àáL(f(x<sup>(i)</sup>; Œ∏), y<sup>(i)</sup>)</div>
                                <div class="formula-explanation">
                                    <strong>Actualizaci√≥n por muestra individual</strong><br>
                                    Alta varianza, convergencia r√°pida
                                </div>
                            </div>
                            <div class="formula-container">
                                <div class="formula-main">Œ∏<sub>(t+1)</sub> = Œ∏<sub>(t)</sub> - (Œ∑/b) Œ£<sub>j=1</sub><sup>b</sup> ‚àáL(...)</div>
                                <div class="formula-explanation">
                                    <strong>b:</strong> Tama√±o del mini-batch (32, 64, 128, 256)<br>
                                    <strong>Compromiso:</strong> Velocidad vs. estabilidad
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <h3 class="section-title">
                                <span class="section-icon">‚öñÔ∏è</span>
                                An√°lisis de Ventajas y Desventajas
                            </h3>
                            <div class="pros-cons-grid">
                                <div class="pros-box">
                                    <h4 class="pros-title">‚úÖ Ventajas</h4>
                                    <ul>
                                        <li>Extremadamente r√°pido para big data</li>
                                        <li>Capacidad de escapar de m√≠nimos locales</li>
                                        <li>Permite aprendizaje online e incremental</li>
                                        <li>Eficiente en memoria (no requiere dataset completo)</li>
                                        <li>Altamente paralelizable en GPU</li>
                                        <li>Escalable a millones de par√°metros</li>
                                    </ul>
                                </div>
                                <div class="cons-box">
                                    <h4 class="cons-title">‚ùå Desventajas</h4>
                                    <ul>
                                        <li>Convergencia ruidosa y oscilante</li>
                                        <li>Puede no converger exactamente al √≥ptimo</li>
                                        <li>Requiere ajuste cuidadoso del learning rate</li>
                                        <li>Alta varianza en las actualizaciones</li>
                                        <li>Sensible al learning rate schedule</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <div class="applications-box">
                                <h3 class="applications-title">üéØ Aplicaciones en Machine Learning</h3>
                                <div class="app-tags">
                                    <span class="app-tag">Deep Learning</span>
                                    <span class="app-tag">Redes Neuronales Convolucionales (CNN)</span>
                                    <span class="app-tag">Redes Neuronales Recurrentes (RNN/LSTM)</span>
                                    <span class="app-tag">Transformers</span>
                                    <span class="app-tag">Modelos de Lenguaje (LLMs)</span>
                                    <span class="app-tag">Computer Vision</span>
                                    <span class="app-tag">Natural Language Processing</span>
                                    <span class="app-tag">Reinforcement Learning</span>
                                </div>
                                <p class="app-description">
                                    SGD es el est√°ndar de facto en deep learning. Pr√°cticamente todas las arquitecturas neuronales modernas (ResNet, BERT, GPT, Vision Transformers) se entrenan con variantes de SGD. Su eficiencia permite entrenar modelos con miles de millones de par√°metros en datasets masivos.
                                </p>
                            </div>
                        </div>

                        <div class="visualization-section">
                            <h3 class="visualization-title">üìä Flujo de Optimizaci√≥n Estoc√°stica</h3>
                            <div class="mermaid">
graph LR
    A[Inicio: Œ∏‚Å∞] --> B[Seleccionar<br/>mini-batch B]
    B --> C[Calcular ‚àáJ Œ∏<br/>solo en B]
    C --> D[Actualizar:<br/>Œ∏ = Œ∏ - Œ∑‚àáJ]
    D --> E{¬øEpoch<br/>completo?}
    E -->|No| B
    E -->|S√≠| F{¬øConvergencia?}
    F -->|No| G[Shuffle data]
    G --> B
    F -->|S√≠| H[Œ∏* √ìptimo]
    style A fill:#415a77,stroke:#0d1b2a,stroke-width:3px,color:#fff
    style H fill:#0d1b2a,stroke:#415a77,stroke-width:3px,color:#fff
    style C fill:#778da9,stroke:#0d1b2a,stroke-width:2px
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- M√âTODO 3: NEWTON -->
            <div class="method-card">
                <div class="method-header">
                    <div class="method-number">M√âTODO 03</div>
                    <h2 class="method-title">M√©todo de Newton</h2>
                </div>
                <div class="method-body">
                    <div class="method-grid">
                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üìã</span>
                                Descripci√≥n
                            </h3>
                            <p class="description-text">
                                El M√©todo de Newton es un algoritmo de segundo orden que utiliza informaci√≥n de curvatura (matriz Hessiana) adem√°s del gradiente. Ofrece convergencia cuadr√°tica cerca del √≥ptimo, alcanzando la soluci√≥n en pocas iteraciones. Sin embargo, el c√°lculo e inversi√≥n de la Hessiana tiene complejidad O(n¬≥), haci√©ndolo inviable para problemas de alta dimensi√≥n. M√©todos quasi-Newton como L-BFGS aproximan la Hessiana evitando su c√°lculo expl√≠cito.
                            </p>
                        </div>

                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üßÆ</span>
                                F√≥rmulas Principales
                            </h3>
                            <div class="formula-container">
                                <div class="formula-main">Œ∏<sub>(t+1)</sub> = Œ∏<sub>(t)</sub> - H<sup>-1</sup>(Œ∏<sub>(t)</sub>) ‚àáJ(Œ∏<sub>(t)</sub>)</div>
                                <div class="formula-explanation">
                                    <strong>H:</strong> Matriz Hessiana (segundas derivadas)<br>
                                    <strong>H<sup>-1</sup>:</strong> Inversa de la Hessiana<br>
                                    Utiliza informaci√≥n de curvatura local
                                </div>
                            </div>
                            <div class="formula-container">
                                <div class="formula-main">H(Œ∏) = ‚àá¬≤J(Œ∏) = [‚àÇ¬≤J/‚àÇŒ∏<sub>i</sub>‚àÇŒ∏<sub>j</sub>]</div>
                                <div class="formula-explanation">
                                    <strong>Dimensi√≥n:</strong> n √ó n matriz<br>
                                    <strong>Complejidad:</strong> O(n¬≤) memoria, O(n¬≥) inversi√≥n
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <h3 class="section-title">
                                <span class="section-icon">‚öñÔ∏è</span>
                                An√°lisis de Ventajas y Desventajas
                            </h3>
                            <div class="pros-cons-grid">
                                <div class="pros-box">
                                    <h4 class="pros-title">‚úÖ Ventajas</h4>
                                    <ul>
                                        <li>Convergencia cuadr√°tica (muy r√°pida cerca del √≥ptimo)</li>
                                        <li>Pocas iteraciones necesarias (t√≠picamente 5-15)</li>
                                        <li>Invariante a transformaciones afines</li>
                                        <li>Alta precisi√≥n en la soluci√≥n final</li>
                                        <li>No requiere ajuste de learning rate</li>
                                        <li>Te√≥ricamente √≥ptimo para problemas convexos</li>
                                    </ul>
                                </div>
                                <div class="cons-box">
                                    <h4 class="cons-title">‚ùå Desventajas</h4>
                                    <ul>
                                        <li>Computacionalmente prohibitivo (O(n¬≥))</li>
                                        <li>Requiere O(n¬≤) memoria para Hessiana</li>
                                        <li>Inviable para alta dimensionalidad (n > 10,000)</li>
                                        <li>Requiere que Hessiana sea invertible</li>
                                        <li>Puede diverger si lejos del √≥ptimo</li>
                                        <li>No paralelizable eficientemente</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <div class="applications-box">
                                <h3 class="applications-title">üéØ Aplicaciones en Machine Learning</h3>
                                <div class="app-tags">
                                    <span class="app-tag">Regresi√≥n Log√≠stica</span>
                                    <span class="app-tag">Modelos Lineales Generalizados (GLM)</span>
                                    <span class="app-tag">L-BFGS (Aproximaci√≥n)</span>
                                    <span class="app-tag">Optimizaci√≥n Convexa</span>
                                    <span class="app-tag">Problemas de Baja Dimensi√≥n</span>
                                    <span class="app-tag">Trust Region Methods</span>
                                </div>
                                <p class="app-description">
                                    Utilizado principalmente en problemas con pocas variables (n < 1,000) y funciones convexas. En ML moderno, se prefieren aproximaciones como L-BFGS que aproximan la Hessiana usando hist√≥rico de gradientes, siendo competitivos en velocidad sin el costo computacional prohibitivo del m√©todo Newton puro.
                                </p>
                            </div>
                        </div>

                        <div class="visualization-section">
                            <h3 class="visualization-title">üìä Flujo de Optimizaci√≥n de Segundo Orden</h3>
                            <div class="mermaid">
graph TD
    A[Inicio: Œ∏‚Å∞] --> B[Calcular ‚àáJ Œ∏]
    B --> C[Calcular Hessiana<br/>H = ‚àá¬≤J Œ∏]
    C --> D[Invertir Hessiana<br/>H‚Åª¬π Costo O n¬≥]
    D --> E[Actualizar:<br/>Œ∏ = Œ∏ - H‚Åª¬π‚àáJ]
    E --> F{¬øConvergencia?}
    F -->|No <br/>5-10 iter| B
    F -->|S√≠| G[Œ∏* √ìptimo]
    style A fill:#415a77,stroke:#0d1b2a,stroke-width:3px,color:#fff
    style G fill:#0d1b2a,stroke:#415a77,stroke-width:3px,color:#fff
    style D fill:#778da9,stroke:#0d1b2a,stroke-width:2px
    style C fill:#778da9,stroke:#0d1b2a,stroke-width:2px
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- M√âTODO 4: PSO -->
            <div class="method-card">
                <div class="method-header">
                    <div class="method-number">M√âTODO 04</div>
                    <h2 class="method-title">Optimizaci√≥n por Enjambre de Part√≠culas (PSO)</h2>
                </div>
                <div class="method-body">
                    <div class="method-grid">
                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üìã</span>
                                Descripci√≥n
                            </h3>
                            <p class="description-text">
                                PSO es un algoritmo metaheur√≠stico bio-inspirado que simula el comportamiento social de bandadas de aves o card√∫menes de peces. Mantiene una poblaci√≥n de soluciones candidatas (part√≠culas) que exploran el espacio de b√∫squeda colaborativamente. Cada part√≠cula ajusta su trayectoria bas√°ndose en su mejor experiencia personal y la mejor experiencia global del enjambre. No requiere gradientes, siendo ideal para funciones no diferenciables o con m√∫ltiples √≥ptimos locales.
                            </p>
                        </div>

                        <div class="section-box">
                            <h3 class="section-title">
                                <span class="section-icon">üßÆ</span>
                                F√≥rmulas Principales
                            </h3>
                            <div class="formula-container">
                                <div class="formula-main">v<sub>i</sub><sup>(t+1)</sup> = w¬∑v<sub>i</sub><sup>(t)</sup> + c‚ÇÅr‚ÇÅ(p<sub>best</sub> - x<sub>i</sub><sup>(t)</sup>) + c‚ÇÇr‚ÇÇ(g<sub>best</sub> - x<sub>i</sub><sup>(t)</sup>)</div>
                                <div class="formula-explanation">
                                    <strong>w:</strong> Peso de inercia (0.4-0.9)<br>
                                    <strong>c‚ÇÅ, c‚ÇÇ:</strong> Coeficientes cognitivo y social (~2.0)<br>
                                    <strong>r‚ÇÅ, r‚ÇÇ:</strong> N√∫meros aleatorios uniformes [0,1]
                                </div>
                            </div>
                            <div class="formula-container">
                                <div class="formula-main">x<sub>i</sub><sup>(t+1)</sup> = x<sub>i</sub><sup>(t)</sup> + v<sub>i</sub><sup>(t+1)</sup></div>
                                <div class="formula-explanation">
                                    <strong>p<sub>best</sub>:</strong> Mejor posici√≥n personal<br>
                                    <strong>g<sub>best</sub>:</strong> Mejor posici√≥n global del enjambre
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <h3 class="section-title">
                                <span class="section-icon">‚öñÔ∏è</span>
                                An√°lisis de Ventajas y Desventajas
                            </h3>
                            <div class="pros-cons-grid">
                                <div class="pros-box">
                                    <h4 class="pros-title">‚úÖ Ventajas</h4>
                                    <ul>
                                        <li>No requiere gradientes (derivative-free)</li>
                                        <li>Excelente para optimizaci√≥n global multimodal</li>
                                        <li>Muy simple de implementar y entender</li>
                                        <li>Pocos hiperpar√°metros a ajustar</li>
                                        <li>Funciona con funciones discontinuas o ruidosas</li>
                                        <li>Buena exploraci√≥n del espacio de b√∫squeda</li>
                                        <li>Paralelizable por naturaleza</li>
                                    </ul>
                                </div>
                                <div class="cons-box">
                                    <h4 class="cons-title">‚ùå Desventajas</h4>
                                    <ul>
                                        <li>Convergencia lenta en b√∫squeda local fina</li>
                                        <li>Sin garant√≠a de √≥ptimo global</li>
                                        <li>Puede converger prematuramente</li>
                                        <li>Requiere muchas evaluaciones de funci√≥n objetivo</li>
                                        <li>Sensible a par√°metros en algunos problemas</li>
                                        <li>No aprovecha estructura del problema</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="section-box" style="grid-column: 1 / -1;">
                            <div class="applications-box">
                                <h3 class="applications-title">üéØ Aplicaciones en Machine Learning</h3>
                                <div class="app-tags">
                                    <span class="app-tag">Hyperparameter Tuning</span>
                                    <span class="app-tag">Neural Architecture Search (NAS)</span>
                                    <span class="app-tag">Feature Selection</span>
                                    <span class="app-tag">Ensemble Learning</span>
                                    <span class="app-tag">Clustering</span>
                                    <span class="app-tag">Optimizaci√≥n Black-Box</span>
                                    <span class="app-tag">AutoML</span>
                                    <span class="app-tag">Problemas NP-Hard</span>
                                </div>
                                <p class="app-description">
                                    PSO brilla en problemas donde el gradiente es inaccesible o poco confiable. Es ampliamente usado en b√∫squeda de hiperpar√°metros, selecci√≥n de caracter√≠sticas, y dise√±o autom√°tico de arquitecturas neuronales. En AutoML, PSO compite efectivamente con m√©todos bayesianos para explorar espacios de configuraci√≥n complejos.
                                </p>
                            </div>
                        </div>

                        <div class="visualization-section">
                            <h3 class="visualization-title">üìä Flujo de Optimizaci√≥n por Enjambre</h3>
                            <div class="mermaid">
graph TD
    A[Inicializar<br/>N part√≠culas] --> B[Evaluar fitness<br/>de cada part√≠cula]
    B --> C[Actualizar p_best<br/>de cada part√≠cula]
    C --> D[Actualizar g_best<br/>del enjambre]
    D --> E[Calcular velocidad<br/>v = w¬∑v + cognitivo + social]
    E --> F[Actualizar posici√≥n<br/>x = x + v]
    F --> G{¬øConvergencia o<br/>max iter?}
    G -->|No| B
    G -->|S√≠| H[g_best = Soluci√≥n]
    style A fill:#415a77,stroke:#0d1b2a,stroke-width:3px,color:#fff
    style H fill:#0d1b2a,stroke:#415a77,stroke-width:3px,color:#fff
    style E fill:#778da9,stroke:#0d1b2a,stroke-width:2px
    style F fill:#778da9,stroke:#0d1b2a,stroke-width:2px
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- COMPARISON TABLE -->
        <div class="comparison-section">
            <h2 class="comparison-title">An√°lisis Comparativo de M√©todos</h2>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Caracter√≠stica</th>
                            <th>Gradient Descent</th>
                            <th>SGD</th>
                            <th>Newton</th>
                            <th>PSO</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Orden del M√©todo</td>
                            <td>Primer orden (‚àáf)</td>
                            <td>Primer orden (‚àáf)</td>
                            <td>Segundo orden (‚àá¬≤f)</td>
                            <td>Orden cero</td>
                        </tr>
                        <tr>
                            <td>Velocidad de Convergencia</td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</span></td>
                        </tr>
                        <tr>
                            <td>Precisi√≥n</td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</span></td>
                        </tr>
                        <tr>
                            <td>Escalabilidad</td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</span></td>
                            <td><span class="rating">‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ</span></td>
                            <td><span class="rating">‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</span></td>
                        </tr>
                        <tr>
                            <td>Complejidad Computacional</td>
                            <td>O(mn)</td>
                            <td>O(bn)</td>
                            <td>O(n¬≥)</td>
                            <td>O(Nn)</td>
                        </tr>
                        <tr>
                            <td>Complejidad de Memoria</td>
                            <td>O(n)</td>
                            <td>O(n)</td>
                            <td>O(n¬≤)</td>
                            <td>O(Nn)</td>
                        </tr>
                        <tr>
                            <td>Requiere Gradientes</td>
                            <td>‚úÖ S√≠</td>
                            <td>‚úÖ S√≠</td>
                            <td>‚úÖ‚úÖ S√≠ + Hessiana</td>
                            <td>‚ùå No</td>
                        </tr>
                        <tr>
                            <td>Convergencia Garantizada</td>
                            <td>‚úÖ (si convexa)</td>
                            <td>‚ö†Ô∏è Probabil√≠stica</td>
                            <td>‚úÖ (local)</td>
                            <td>‚ùå No garantizada</td>
                        </tr>
                        <tr>
                            <td>Paralelizaci√≥n</td>
                            <td>‚ùå Dif√≠cil</td>
                            <td>‚úÖ Excelente (GPU)</td>
                            <td>‚ùå Muy dif√≠cil</td>
                            <td>‚úÖ Natural</td>
                        </tr>
                        <tr>
                            <td>Mejor Caso de Uso</td>
                            <td>Datasets peque√±os</td>
                            <td>Deep Learning</td>
                            <td>Pocos par√°metros</td>
                            <td>Opt. global sin gradientes</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p style="text-align: center; margin-top: 30px; font-size: 0.95em; color: var(--oxford-blue);">
                <strong>Notaci√≥n:</strong> m = tama√±o del dataset | b = tama√±o del batch | n = n√∫mero de par√°metros | N = n√∫mero de part√≠culas
            </p>
        </div>

        <!-- FOOTER -->
        <footer>
            <div class="footer-content">
                <div class="references-section">
                    <h2 class="references-title">Referencias Bibliogr√°ficas</h2>
                    <ol class="references-list">
                        <li>
                            <strong>Ruder, S.</strong> (2016). <em>An overview of gradient descent optimization algorithms.</em> arXiv preprint arXiv:1609.04747.
                            <a href="https://arxiv.org/abs/1609.04747" target="_blank">https://arxiv.org/abs/1609.04747</a>
                            <span class="ref-note">Revisi√≥n exhaustiva de m√©todos de optimizaci√≥n basados en gradientes, incluyendo an√°lisis detallado de SGD, Momentum, Adam, RMSprop y sus variantes.</span>
                        </li>
                        
                        <li>
                            <strong>Goodfellow, I., Bengio, Y., & Courville, A.</strong> (2016). <em>Deep Learning.</em> MIT Press. Cap√≠tulo 8: "Optimization for Training Deep Models."
                            <span class="ref-note">Texto fundamental que cubre teor√≠a y pr√°ctica de optimizaci√≥n en deep learning, desde fundamentos matem√°ticos hasta implementaciones modernas.</span>
                        </li>
                        
                        <li>
                            <strong>Nocedal, J., & Wright, S. J.</strong> (2006). <em>Numerical Optimization</em> (2nd ed.). Springer.
                            <span class="ref-note">Referencia cl√°sica en optimizaci√≥n num√©rica, con tratamiento riguroso del m√©todo de Newton, m√©todos quasi-Newton y an√°lisis de convergencia.</span>
                        </li>
                        
                        <li>
                            <strong>Kennedy, J., & Eberhart, R.</strong> (1995). "Particle swarm optimization." <em>Proceedings of ICNN'95 - International Conference on Neural Networks</em>, 4, 1942-1948.
                            <span class="ref-note">Art√≠culo seminal que introduce PSO, inspirado en el comportamiento emergente de sistemas biol√≥gicos sociales.</span>
                        </li>
                        
                        <li>
                            <strong>Shi, Y., & Eberhart, R.</strong> (1998). "A modified particle swarm optimizer." <em>IEEE International Conference on Evolutionary Computation Proceedings</em>, 69-73.
                            <span class="ref-note">Introduce el concepto fundamental de peso de inercia en PSO, mejorando significativamente el balance exploraci√≥n-explotaci√≥n.</span>
                        </li>
                        
                        <li>
                            <strong>Bottou, L., Curtis, F. E., & Nocedal, J.</strong> (2018). "Optimization methods for large-scale machine learning." <em>SIAM Review</em>, 60(2), 223-311.
                            <span class="ref-note">Revisi√≥n comprehensiva y moderna de m√©todos de optimizaci√≥n para ML a gran escala, conectando teor√≠a cl√°sica con pr√°ctica contempor√°nea.</span>
                        </li>
                        
                        <li>
                            <strong>Kingma, D. P., & Ba, J.</strong> (2014). "Adam: A method for stochastic optimization." arXiv preprint arXiv:1412.6980.
                            <a href="https://arxiv.org/abs/1412.6980" target="_blank">https://arxiv.org/abs/1412.6980</a>
                            <span class="ref-note">Introduce Adam, uno de los optimizadores m√°s populares y efectivos en deep learning, basado en estimaciones adaptativas de momentos.</span>
                        </li>
                        
                        <li>
                            <strong>Poli, R., Kennedy, J., & Blackwell, T.</strong> (2007). "Particle swarm optimization: An overview." <em>Swarm Intelligence</em>, 1(1), 33-57.
                            <span class="ref-note">Revisi√≥n comprehensiva del estado del arte en PSO, cubriendo teor√≠a, variantes algor√≠tmicas y aplicaciones pr√°cticas.</span>
                        </li>

                        <li>
                            <strong>Boyd, S., & Vandenberghe, L.</strong> (2004). <em>Convex Optimization.</em> Cambridge University Press.
                            <span class="ref-note">Texto fundamental sobre optimizaci√≥n convexa, con √©nfasis en dualidad, m√©todos de punto interior y aplicaciones en ML.</span>
                        </li>

                        <li>
                            <strong>Nesterov, Y.</strong> (2018). <em>Lectures on Convex Optimization</em> (2nd ed.). Springer.
                            <span class="ref-note">Tratamiento avanzado de m√©todos de optimizaci√≥n, incluyendo m√©todos acelerados de gradiente y an√°lisis de complejidad computacional.</span>
                        </li>
                    </ol>
                </div>

                <div class="footer-info">
                    <div class="footer-logos">
                        <img src="https://www.uacj.mx/acerca_de/Imagen-Institucional-UACJ_files/firma%20institucional%20uacj-vertical-%202015-color-sin%20fondo.png" 
                             alt="UACJ" class="footer-logo">
                        <img src="https://media.licdn.com/dms/image/v2/D560BAQGT-hIyClMhDg/company-logo_400_400/B56ZUrUBmmGQAY-/0/1740188424995?e=2147483647&v=beta&t=WdaQxhUQ6hOSC2RPMI20RCKtFtgRuKZe7rssOYykFWU" 
                             alt="MIAAD" class="footer-logo" style="border-radius: 10px;">
                    </div>
                    <p style="font-size: 1.1em; margin: 15px 0;">
                        <strong>Maestr√≠a en Inteligencia Artificial y Anal√≠tica de Datos</strong>
                    </p>
                    <p style="color: var(--silver-lake-blue);">
                        Universidad Aut√≥noma de Ciudad Ju√°rez<br>
                        Octubre 2025
                    </p>
                    <p style="margin-top: 20px; font-size: 0.9em;">
                        <a href="https://rebull.org/miaad/mate/infografia_optimizacion_numerica" 
                           style="color: var(--platinum); text-decoration: none; border-bottom: 1px solid var(--platinum);">
                            üîó rebull.org/miaad/mate/infografia_optimizacion_numerica
                        </a>
                    </p>
                </div>
            </div>
        </footer>
    </div>
</body>
</html>